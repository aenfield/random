---
title: "Chapter 3, dplyr"
output: html_notebook
---

```{r}
library(nycflights13)
library(tidyverse)
```

```{r}
flights
```

```{r}
summary(flights)
```

```{r}
filter(flights, month == 1, day == 1)
```

```{r}
(jan1 <- filter(flights, month == 1, day == 1))
```

```{r}
(near(sqrt(2)^2, 2))  # parans here to output this result too - could also use print(...)
near(1/49*49, 1)
```

```{r}
#nov_dec <- filter(flights, month == 11 | month == 12)  # same as next line
nov_dev <- filter(flights, month %in% c(11, 12))
```

De Morgan's law to return flights that weren't delayed - on departure or arrival - by more than two hours. Remember that !(x & y) is the same as (!x | !y), and !(x | y) is the same as (!x & !y).
```{r}
filter(flights, !(arr_delay > 120 | dep_delay > 120))
```
```{r}
filter(flights, arr_delay <= 120, dep_delay <= 120) 
```

"Whenever you start using complicated, multipart expressions in filter(), consider making them explicit variables instead. This makes it much easier to check your work."

```{r}
filter(flights, arr_delay >= 120)
```

```{r}
filter(flights, dest == "IAH" | dest == "HOU")
```

```{r}
filter(flights, carrier == "UA" | carrier == "AA" | carrier == "DL")
```

```{r}
filter(flights, carrier %in% c("UA","AA","DL"))
```

```{r}
filter(flights, month %in% c(7,8,9))
```

```{r}
filter(flights, arr_delay >= 120 & dep_delay <= 0)
```

```{r}
filter(flights, dep_delay >= 60 & arr_delay <= 30)
```


```{r}
filter(flights, dep_time >= 0 & dep_time <= 0600)
```

```{r}
filter(flights, between(dep_time, 0, 600))
```

```{r}
sum(is.na(flights$dep_time))
```
```{r}
filter(flights, is.na(dep_time))
```

```{r}
arrange(flights, year, month, day)
```

```{r}
arrange(flights, desc(arr_delay))
```

```{r}
df <- tibble(x = c(5, 2, NA))
arrange(df, x)
```

```{r}
arrange(flights, desc(is.na(dep_time)))
```
```{r}
arrange(flights, desc(arr_delay))
```

```{r}
arrange(flights, dep_delay)
```

```{r}
arrange(flights, air_time)
```

```{r}
arrange(flights, desc(distance))
```

```{r}
arrange(flights, distance)
```

```{r}
select(flights, year, month, day)
```

```{r}
select(flights, year:day)
```

```{r}
select(flights, -(year:day))
```

```{r}
rename(flights, tail_num = tailnum)
```

Two things interesting about the above:

* First, remember that changes never happen in place, so the statement above changes the column name and returns the resulting df, w/ the changed name. But it doesn't save/modify the flights var - that one still has the original column name. If I was to assign the result of the above line to flights then I would create a new local var called flights that points to a df w/ the changed column name. To revert back to the original df, I'd do an rm(flights) to delete the local variable reference, after which the reference in the nycflights13 library would be the one that was visible, per http://stackoverflow.com/questions/25167478/restore-default-r-dataset-after-edits.
* Second, the ordering of the second param was the opposite of what I was expecting. Here's what works: the first name (tail_num here) is the new name of the column, and it gets the values of the second name (tailnum), and then, i think, rename must automatically drop the tailnum column. I was thinking that it should be opposite - for ex, that the first param was the key to look up in the set of cols, and then the second param was the column that it should hold. I see the logic of the first approach.

```{r}
select(flights, tailnum, tailnum, arr_delay)
```

```{r}
vars <- c("year", "month", "day", "dep_delay")
select(flights, one_of(vars))
```
So, it looks like you can use one_of to select all the columns w/ names in a vector - i.e., as opposed to specifying the names in the code itself.

```{r}
select(flights, contains("TIME"))
```
By default, the helpers - like contain, one_of, etc. (documented in the "Select helpers" doc that you can get with things liKE one_of?) have ignore.case set to TRUE. 

```{r}
select(flights, contains("TIME", ignore.case = FALSE))
```

```{r}
flights_sml <- select(flights,
                      year:day,
                      ends_with("delay"),
                      distance,
                      air_time)
mutate(flights_sml,
       gain = arr_delay - dep_delay,
       speed = distance / air_time * 60,
       gain_per_hour = gain / air_time * 60)
```

```{r}
transmute(flights, 
          gain = arr_delay - dep_delay,
          speed = distance / air_time * 60)
```

%/% and %% are integer division (drop remainder) and remainder, respectively. They can be used to break up integers into pieces, like so:
```{r}
transmute(flights,
          dep_time,
          hour = dep_time %/% 100,
          minute = dep_time %% 100)
```

Good point: "Logarithms are an incredibly useful transformation for dealing with data that ranges across multiple orders of magnitude. They also convert multiplicative relationships to additive. All else being equal [he] recommends using log2() because it's easy to interpret: a difference of 1 on the log scale corresponds to a doubling on the original scale and a difference of -1 corresponds to halving."

```{r}
(x <- 1:10)
lag(x)
lead(x)
```

In chapter three there's also stuff about cummean, and rolling aggregates recommending the RcppRoll package
```{r}
x
cumsum(x)
cummean(x)
```

```{r}
(y <- c(1,2,2,NA,3,4))
desc(y) # 'transforms a vector into a format that will be sorted in descending order'
min_rank(y)
min_rank(desc(y))
```

```{r}
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
```

```{r}
flights_a = mutate(flights, 
          dep_time_mins_since_midnight = ((dep_time %/% 100) * 60) + dep_time %% 100,
          sched_dep_time_mins_since_midnight = ((sched_dep_time %/% 100) * 60) + sched_dep_time %% 100)
flights_a
```

```{r}
transmute(flights,
          air_time,
          arr_time,
          dep_time,
          air_time_second = arr_time - dep_time
          )
```

```{r}
arrange(flights, desc(dep_delay))
```

```{r}
summarize(flights, delay = mean(dep_delay, na.rm = TRUE))
```
```{r}
mean(flights$dep_delay, na.rm = TRUE)
```
summarize - which collapses a df to a single row - is more useful with group_by. With group_by, summarize runs on each group instead of the whole df.
```{r}
by_day = group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

"The group_by() and summarize() functions are one of the tools that you'll use most commonly with dplyr: grouped summaries."

```{r}
by_dest <- group_by(flights, dest)
delay <- summarize(by_dest,
                   count = n(),
                   dist = mean(distance, na.rm = TRUE),
                   delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dest != "HNL")

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) + 
  geom_smooth(se = FALSE)
```
This plot says that delays increase with distances up to ~750 miles and then decrease. Perhaps with longer flights, there's more ability to make up departure delays in the air?

Naming things is hard, and takes time. Above, we have to name a few different interim data frames even though they're just interim. Instead, we can avoid the naming, and make the code clearer and shorter, using the pipe.
```{r}
delays <- flights %>%
  group_by(dest) %>%
  summarize(
    count = n(),
    dist = mean(distance, na.rm=TRUE),
    delay = mean(arr_delay, na.rm=TRUE)
  ) %>%
  filter(count > 20, dest != "HNL")

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
```
```{r}
flights %>% group_by(year, month, day) %>% summarize(mean = mean(dep_delay, na.rm=TRUE))
```
```{r}
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% group_by(year, month, day) %>% summarize(mean = mean(dep_delay))
```

Always a good idea to include a count (n()) or count of non-missing values (sum(!is.na(x))) to make sure you don't draw conclusions based on small amounts of data.

Here's a 'frequency polygon' - basically a histogram made of lines, per the docs (i.e., a density plot?). This says some planes have an average delay of 300m/5hrs.
```{r}
delays <- not_cancelled %>% group_by(tailnum) %>% summarize(delay = mean(arr_delay))

ggplot(data = delays, mapping = aes(x = delay)) +
  geom_freqpoly(binwidth = 10)
```
To see more of what's going on, let's draw a scatterplot showing number of flights versus average delay - what was y is now on the x axis.
```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay, na.rm=TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/10)
```
So, this is showing what we almost always see: whenever we plot a mean or other summary vs group size, the higher the number of samples/the number of items in a group, the smaller the variation. Some planes/tail numbers with about 50 or fewer flights have very high (or relatively low) average delays. But once you get more and more flights for a single tail number, the average delay for that tail number gets smaller and smaller.

It's also useful to filter out the groups w/ the smallest numbers of observations, to see more of the pattern and less of the extreme variation in the smallest groups. This also shows a handy way to integrate ggplot2 into dplyr (which necessitates switching between %>% and + - it does mean you don't need to specify the data param in the ggplot call).
```{r}
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes(x = n, y = delay)) +
    geom_point(alpha = 1/10)
```

```{r}
batting = as_tibble(Lahman::Batting)

batters <- batting %>%
  group_by(playerID) %>%
  summarize(
    ba = sum(H, na.rm=TRUE) / sum(AB, na.rm=TRUE),
    ab = sum(AB, na.rm=TRUE)
  )

batters %>% filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() + 
    geom_smooth(se = FALSE)
```

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    avg_delay_all = mean(arr_delay),
    avg_delay_positive = mean(arr_delay[arr_delay > 0])
  )
```

```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarize(
    distance_sd = sd(distance)
  ) %>%
  arrange(desc(dist))
```

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    first = min(dep_time),
    last = max(dep_time),
    q_50 = quantile(dep_time, 0.5),
    median = median(dep_time)
  )
```
```{r}
not_cancelled %>% 
  group_by(year, month, day) %>%
  mutate(r = min_rank(desc(dep_time))) %>%
  filter(r %in% range(r))
```

```{r}
# which dests have the most carriers?
not_cancelled %>%
  group_by(dest) %>%
  summarize(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```

```{r}
# count of flights to each destination
not_cancelled %>%
  count(dest) %>% # looks like this is the same as a group_by(dest) and then summarize(n = n())
  arrange(desc(n)) # count gives us a variable named n, and we can sort on it here
```

```{r}
# you can "count" - really, sum the vals in a particular column instead of just counting rows by using the weight - wt - param. this would
# have been helpful in my work in Python with Edge feedback where i have a 'Cnt' field that I want to sum

# this'll sum and return the total number of miles each plane has flown
not_cancelled %>%
  count(tailnum, wt = distance)
```
```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarize(n = n())
```



```{r}
# how many flights left before 5a? (delayed flights often from the prev day)
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(n_early = sum(dep_time < 500))
```

```{r}
# what prop. of flights are delayed by more than an hour?
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(hour_perc = mean(arr_delay > 60))
```

```{r}
daily <- group_by(flights, year, month, day)
(per_day <- summarize(daily, flights = n()))
```
```{r}
(per_month = summarize(per_day, flights = sum(flights)))
```

```{r}
(per_year = summarize(per_month, flights=sum(flights)))
```

```{r}
daily %>%
  ungroup() %>% # no longer grouped by provided fields
  summarize(flights=n())
```

```{r}
# find the worst members of each group
flights_sml %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

```{r}
# all groups bigger than a threshold
popular_dests <- flights %>%
  group_by(dest) %>%
  filter(n() > 365)
popular_dests
```



# To remember

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).
